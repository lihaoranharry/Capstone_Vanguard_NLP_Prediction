{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     41
    ]
   },
   "outputs": [],
   "source": [
    "def single_read_in_text(file_path,file_name):\n",
    "    '''\n",
    "    input:\n",
    "    file_path: path of a individule csv file e.g. location of 21centfoxinc_sec_files.csv\n",
    "    file_name: name of the file e.g 21centfoxinc_sec_files.csv\n",
    "    \n",
    "    output:\n",
    "    a sigle pandas dataframe with all the original columns from the input file + a column for the 'cleaned' data\n",
    "    \n",
    "    dev:\n",
    "    1) can add more output columns for features\n",
    "    2) can further clean the data \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## read in single csv to pandas \n",
    "    individule_csv = pd.read_csv(file_path+\"/\"+file_name)\n",
    "    raw_texts = []\n",
    "    clean_texts = []\n",
    "    \n",
    "    ## create a connection with the url link and readin the raw file\n",
    "    for url in individule_csv['sec_full_path']:\n",
    "        print(url)\n",
    "        raw_texts.append([url,request.urlopen(url).read().decode('utf8')])\n",
    "    \n",
    "    ## clean the raw file by:\n",
    "    ## 1. break the text by \"\\n\"\n",
    "    ## 2. remove the spaces in the front of and after each \"\\n\" \n",
    "    for raw_file in raw_texts:\n",
    "        clean_texts.append([raw_file[0],list(filter(None, [i.strip() for i in raw_file[1].split('\\n')]))])\n",
    "        ## more columns, features, data cleanings can be put here\n",
    "    \n",
    "    ## merge back to the original read in dataframe \n",
    "    clean_texts_df = pd.DataFrame(clean_texts)\n",
    "    clean_texts_df.columns = ['sec_full_path', 'text']\n",
    "    merged_df = pd.merge(left = individule_csv, right = clean_texts_df, on = 'sec_full_path')\n",
    "    \n",
    "    ## add one more column to indicate the file name \n",
    "    merged_df['file_name'] = file_name\n",
    "    return merged_df\n",
    "\n",
    "def folder_read_in_text(folder_path, ext = '.csv'):\n",
    "    '''\n",
    "    input: \n",
    "    folder_path: path of a individule csv file e.g. location of 21centfoxinc_sec_files.csv\n",
    "    ext: extension of the files that are interested, default to be .csv \n",
    "    \n",
    "    output:\n",
    "    a sigle pandas dataframe with all the original columns from all the input files inside the folder\n",
    "    + a column for the 'cleaned' data\n",
    "    + a column for the file name \n",
    "    \n",
    "    Utilize the single_read_in_text function \n",
    "    '''\n",
    "    file = []\n",
    "    direc = folder_path \n",
    "\n",
    "    # Select only files with the ext extension\n",
    "    txt_files = [i for i in os.listdir(direc) if os.path.splitext(i)[1] == ext]\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    ## Utilize the single_read_in_text function to process data\n",
    "    for i in txt_files:\n",
    "        temp_df = temp_df.append(single_read_in_text(file_path = folder_path,file_name = i), ignore_index=True)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#single_read_in_text('C:/Users/li haoran/Desktop/New folder','21centfoxinc_sec_files.csv')\n",
    "working_file = folder_read_in_text(folder_path='C:/Users/li haoran/Desktop/sec files', ext = '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file.to_csv('C:/Users/li haoran/Desktop/sec files/merged_all.csv', sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
