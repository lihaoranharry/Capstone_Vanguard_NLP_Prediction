{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     49
    ]
   },
   "outputs": [],
   "source": [
    "def single_read_in_text(file_path,file_name):\n",
    "    '''\n",
    "    input:\n",
    "    file_path: path of a individule csv file e.g. location of 21centfoxinc_sec_files.csv\n",
    "    file_name: name of the file e.g 21centfoxinc_sec_files.csv\n",
    "    \n",
    "    output:\n",
    "    a sigle pandas dataframe with all the original columns from the input file + a column for the 'cleaned' data\n",
    "    \n",
    "    dev:\n",
    "    1) can add more output columns for features\n",
    "    2) can further clean the data \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## read in single csv to pandas \n",
    "    individule_csv = pd.read_csv(file_path+\"/\"+file_name)\n",
    "    raw_texts = []\n",
    "    clean_texts = []\n",
    "    \n",
    "    ## create a connection with the url link and readin the raw file\n",
    "    for url in individule_csv['sec_full_path']:\n",
    "        print(url)\n",
    "        raw_texts.append([url,request.urlopen(url).read().decode('utf8')])\n",
    "    \n",
    "    ## clean the raw file by:\n",
    "    ## 1. remove html tags \n",
    "    ## 2. break the text by \"\\n\"\n",
    "    ## 3. remove the spaces in the front of and after each \"\\n\"\n",
    "    \n",
    "    for raw_file in raw_texts:\n",
    "        \n",
    "        \n",
    "        \n",
    "        clean_texts.append([raw_file[0],\n",
    "                            '%%'.join(list(filter(None,\n",
    "                                                 [re.sub('[\\t]+', ' ', i.strip()) for \n",
    "                                                  i in BeautifulSoup(raw_file[1], \"lxml\").text.split('\\n')])))])\n",
    "        ## more columns, features, data cleanings can be put here\n",
    "    \n",
    "    ## merge back to the original read in dataframe \n",
    "    clean_texts_df = pd.DataFrame(clean_texts)\n",
    "    clean_texts_df.columns = ['sec_full_path', 'text']\n",
    "    merged_df = pd.merge(left = individule_csv, right = clean_texts_df, on = 'sec_full_path')\n",
    "    \n",
    "    ## add one more column to indicate the file name \n",
    "    merged_df['file_name'] = file_name\n",
    "    return merged_df\n",
    "\n",
    "def folder_read_in_text(folder_path, ext = '.csv'):\n",
    "    '''\n",
    "    input: \n",
    "    folder_path: path of a individule csv file e.g. location of 21centfoxinc_sec_files.csv\n",
    "    ext: extension of the files that are interested, default to be .csv \n",
    "    \n",
    "    output:\n",
    "    a sigle pandas dataframe with all the original columns from all the input files inside the folder\n",
    "    + a column for the 'cleaned' data\n",
    "    + a column for the file name \n",
    "    \n",
    "    Utilize the single_read_in_text function \n",
    "    '''\n",
    "    file = []\n",
    "    direc = folder_path \n",
    "\n",
    "    # Select only files with the ext extension\n",
    "    txt_files = [i for i in os.listdir(direc) if os.path.splitext(i)[1] == ext]\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    ## Utilize the single_read_in_text function to process data\n",
    "\n",
    "    for i in txt_files:\n",
    "        temp_df = temp_df.append(single_read_in_text(file_path = folder_path,file_name = i), ignore_index=True)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#single_read_in_text('C:/Users/li haoran/Desktop/New folder','21centfoxinc_sec_files.csv')\n",
    "working_file = folder_read_in_text(folder_path='C:/Users/li haoran/Documents/GitHub/Capstone_Vanguard_NLP_Prediction/Inputs',\n",
    "                                   ext = '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file.to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data.csv', sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/li haoran/Desktop/sec files/sample.csv'\n",
    "sample_read_back = pd.read_csv(file_path, sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_read_back['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_read_back['sec_full_path'][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
