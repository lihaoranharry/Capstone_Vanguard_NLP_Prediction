{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import requests\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import nltk\n",
    "from nltk import word_tokenize, everygrams\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     48
    ]
   },
   "outputs": [],
   "source": [
    "def single_read_in_text(file_path,file_name):\n",
    "    '''\n",
    "    input:\n",
    "    file_path: path of a individule csv file e.g. location of 21centfoxinc_sec_files.csv\n",
    "    file_name: name of the file e.g 21centfoxinc_sec_files.csv\n",
    "    \n",
    "    output:\n",
    "    a sigle pandas dataframe with all the original columns from the input file + a column for the 'cleaned' data\n",
    "    \n",
    "    dev:\n",
    "    1) can add more output columns for features\n",
    "    2) can further clean the data \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ## read in single csv to pandas \n",
    "    individule_csv = pd.read_csv(file_path+\"/\"+file_name)\n",
    "    raw_texts = []\n",
    "    clean_texts = []\n",
    "    \n",
    "    ## create a connection with the url link and readin the raw file\n",
    "    for url in individule_csv['sec_full_path']:\n",
    "        print(url)\n",
    "        raw_texts.append([url,request.urlopen(url).read().decode('utf8')])\n",
    "    \n",
    "    ## clean the raw file by:\n",
    "    ## 1. remove html tags \n",
    "    ## 2. break the text by \"\\n\"\n",
    "    ## 3. remove the spaces in the front of and after each \"\\n\"\n",
    "    \n",
    "    for raw_file in raw_texts:\n",
    "        \n",
    "        \n",
    "        \n",
    "        clean_texts.append([raw_file[0],\n",
    "                            '%%'.join(list(filter(None,\n",
    "                                                 [re.sub('[\\t]+', ' ', i.strip()) for \n",
    "                                                  i in BeautifulSoup(raw_file[1], \"lxml\").text.split('\\n')])))])\n",
    "        ## more columns, features, data cleanings can be put here\n",
    "    \n",
    "    ## merge back to the original read in dataframe \n",
    "    clean_texts_df = pd.DataFrame(clean_texts)\n",
    "    clean_texts_df.columns = ['sec_full_path', 'text']\n",
    "    merged_df = pd.merge(left = individule_csv, right = clean_texts_df, on = 'sec_full_path')\n",
    "    \n",
    "    ## add one more column to indicate the file name \n",
    "    merged_df['file_name'] = file_name\n",
    "    return merged_df\n",
    "def folder_read_in_text(folder_path, ext = '.csv'):\n",
    "    '''\n",
    "    input: \n",
    "    folder_path: path of a individule csv file e.g. location of 21centfoxinc_sec_files.csv\n",
    "    ext: extension of the files that are interested, default to be .csv \n",
    "    \n",
    "    output:\n",
    "    a sigle pandas dataframe with all the original columns from all the input files inside the folder\n",
    "    + a column for the 'cleaned' data\n",
    "    + a column for the file name \n",
    "    \n",
    "    Utilize the single_read_in_text function \n",
    "    '''\n",
    "    file = []\n",
    "    direc = folder_path \n",
    "\n",
    "    # Select only files with the ext extension\n",
    "    txt_files = [i for i in os.listdir(direc) if os.path.splitext(i)[1] == ext]\n",
    "    temp_df = pd.DataFrame()\n",
    "    \n",
    "    ## Utilize the single_read_in_text function to process data\n",
    "\n",
    "    for i in txt_files:\n",
    "        temp_df = temp_df.append(single_read_in_text(file_path = folder_path,file_name = i), ignore_index=True)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#single_read_in_text('C:/Users/li haoran/Desktop/New folder','21centfoxinc_sec_files.csv')\n",
    "working_file = folder_read_in_text(folder_path='C:/Users/li haoran/Documents/GitHub/Capstone_Vanguard_NLP_Prediction/Inputs',\n",
    "                                   ext = '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_file.to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data.csv', sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/li haoran/Desktop/sec files/cleaned_data.csv'\n",
    "cleaned_data = pd.read_csv(file_path, sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "cleaned_data['only_eng_words'] = cleaned_data['text'].apply(lambda x: \" \".join(w for w in nltk.wordpunct_tokenize(x) \\\n",
    "                                      if w.lower() in words))\n",
    "cleaned_data['evy_gram_1_3'] =cleaned_data['only_eng_words'].apply(lambda x: [' '.join(ng) for ng in everygrams(word_tokenize(x), 1, 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th colspan=\"2\" halign=\"left\">doccount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21centfoxinc_sec_files.csv</td>\n",
       "      <td>1048</td>\n",
       "      <td>3978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attinc_sec_files.csv</td>\n",
       "      <td>555</td>\n",
       "      <td>3383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cbscorp_sec_files.csv</td>\n",
       "      <td>385</td>\n",
       "      <td>2578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comcastcorp_sec_files.csv</td>\n",
       "      <td>277</td>\n",
       "      <td>2735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>verizoncom_sec_files.csv</td>\n",
       "      <td>525</td>\n",
       "      <td>3319.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    file_name doccount        \n",
       "                                 count     sum\n",
       "0  21centfoxinc_sec_files.csv     1048  3978.0\n",
       "1        attinc_sec_files.csv      555  3383.0\n",
       "2       cbscorp_sec_files.csv      385  2578.0\n",
       "3   comcastcorp_sec_files.csv      277  2735.0\n",
       "4    verizoncom_sec_files.csv      525  3319.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data[['file_name', 'doccount']]\\\n",
    ".groupby(['file_name'])\\\n",
    ".agg(['count','sum'])\\\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data_updated.csv', sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[cleaned_data['file_name']=='21centfoxinc_sec_files.csv']\\\n",
    ".to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data_updated_21centfoxinc_sec_files.csv', sep='|', encoding='utf-8')\n",
    "\n",
    "cleaned_data[cleaned_data['file_name']=='attinc_sec_files.csv']\\\n",
    ".to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data_updated_attinc_sec_files.csv', sep='|', encoding='utf-8')\n",
    "\n",
    "cleaned_data[cleaned_data['file_name']=='cbscorp_sec_files.csv']\\\n",
    ".to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data_updated_cbscorp_sec_files.csv', sep='|', encoding='utf-8')\n",
    "\n",
    "cleaned_data[cleaned_data['file_name']=='comcastcorp_sec_files.csv']\\\n",
    ".to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data_updated_comcastcorp_sec_files.csv', sep='|', encoding='utf-8')\n",
    "\n",
    "cleaned_data[cleaned_data['file_name']=='verizoncom_sec_files.csv']\\\n",
    ".to_csv('C:/Users/li haoran/Desktop/sec files/cleaned_data_updated_verizoncom_sec_files.csv', sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full data\n",
    "file_path = 'C:/Users/li haoran/Desktop/sec files/cleaned_data.csv'\n",
    "cleaned_data = pd.read_csv(file_path, sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaned_data_updated_verizoncom_sec_files.csv\n",
    "file_path = 'C:/Users/li haoran/Desktop/sec files/cleaned_data_updated_verizoncom_sec_files.csv'\n",
    "cleaned_verizon_data = pd.read_csv(file_path, sep='|', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = cleaned_data[['file_name', 'doccount']]\\\n",
    ".groupby(['file_name'])\\\n",
    ".agg(['count','sum'])\\\n",
    ".reset_index()\n",
    "print(list(table1))\n",
    "table1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace1 = go.Bar(x = table1['file_name'], \n",
    "                y = table1['doccount']['count'],\n",
    "                name = 'filing count')\n",
    "\n",
    "trace2 = go.Bar(x = table1['file_name'],\n",
    "                y = table1['doccount']['sum'],\n",
    "                name = 'document count')\n",
    "\n",
    "data = [trace1,trace2]\n",
    "\n",
    "\n",
    "iplot({\n",
    "    \"data\":data,\n",
    "    \"layout\":go.Layout(title=\"Distribution of number of emails received\", \n",
    "                       xaxis={'title':'Num of emails'}, \n",
    "                       yaxis={'title':'Percentage of people received %'})})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table2 = cleaned_data[['file_name','form','doccount']]\\\n",
    ".groupby(['file_name','form'])\\\n",
    ".agg(['count','sum'])\\\n",
    ".sort_values(by=['file_name'])\\\n",
    ".reset_index()\n",
    "print(list(table2))\n",
    "table2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "It is very very very very hard to parse old sec financial table, more recent files are easier \n",
    "\n",
    "https://github.com/ragraw26/Edgar-COMPANY-FILINGS-Web-Scrapping-Data-Analysis/blob/master/Data%20Scrapping/Team_5_Part1_Report.pdf\n",
    "\n",
    "https://www.sec.gov/cgi-bin/viewer?action=view&cik=732712&accession_number=0001193125-10-041685&xbrl_type=v\n",
    "\n",
    "https://www.codeproject.com/Articles/1227268/Accessing-Financial-Reports-in-the-EDGAR-Database\n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all-next-and-find-next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.gov/Archives/edgar/data/732712/0000950133-94-000018.txt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_verizon_data[cleaned_verizon_data['form']=='8-K']['sec_full_path'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-K</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-Q</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8-K</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   form file_name\n",
       "            count\n",
       "0  10-K        21\n",
       "1  10-Q        74\n",
       "2   8-K       430"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_verizon_data[['file_name','form']]\\\n",
    ".groupby(['form'])\\\n",
    ".agg(['count'])\\\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_html = 'https://www.sec.gov/Archives/edgar/data/732712/0000950109-94-000587.txt'\n",
    "test_file = request.urlopen(test_html).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = re.compile(r'\\table\\b | \\bCAPTION\\b', flags=re.I | re.X)\n",
    "#r = re.compile(r'\\table\\b\\bCAPTION\\b', flags=re.I | re.X)\n",
    "r = re.compile(r'\\<table\\>\\s*\\<caption\\>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(test_file,'html.parser')\n",
    "table = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<table>\n",
       "<caption> \n",
       "                                                                                          Held\n",
       "        Name                  Age                      Office                             Since\n",
       "        ----                  ---                      ------                             -----\n",
       "<s> <c> <c> <c>  \n",
       "Raymond W. Smith...........   56  Chairman of the Board and Chief Executive Officer        1989\n",
       "James G. Cullen............   51  President                                                1993\n",
       "William O. Albertini.......   50  Vice President and Chief Financial Officer               1991\n",
       "Joseph T. Ambrozy..........   54  Vice President - Strategic Planning                      1992\n",
       "Lawrence T. Babbio, Jr.....   49  Chairman, President and Chief Executive Officer,         1991\n",
       "                                        Bell Atlantic Enterprises International, Inc.\n",
       "P. Alan Bulliner...........   50  Vice President - Corporate Secretary and Counsel         1992  \n",
       "Barbara L. Connor..........   43  Vice President - Finance and Controller and Treasurer    1993 \n",
       "Charles W. Crist...........   50  Vice President - Human Resources                         1990 \n",
       "John F. Gamba..............   55  Group President, Network Technologies and Systems,       1993\n",
       "                                        Bell Atlantic Network Services, Inc.\n",
       "Bruce S. Gordon............   48  Group President - Consumer and Small Business Services,  1993\n",
       "                                        Bell Atlantic Network Services, Inc.               \n",
       "Stuart C. Johnson..........   51  Group President, Large Business and Information          1993\n",
       "                                        Services, Bell Atlantic Network Services, Inc.     \n",
       "Brian J. Kelly.............   59  Group President, Network Operations,                     1993\n",
       "                                        Bell Atlantic Network Services, Inc.               \n",
       "Robert M. Valentini........   50  President and Chief Executive Officer, Bell Atlantic -   1988\n",
       "                                        Pennsylvania, Inc.\n",
       "James R. Young.............   42  Vice President and General Counsel                       1992\n",
       "</c></c></c></s></caption></table>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n \\n                                                                                          Held\\n        Name                  Age                      Office                             Since\\n        ----                  ---                      ------                             -----\\n     \\nRaymond W. Smith...........   56  Chairman of the Board and Chief Executive Officer        1989\\nJames G. Cullen............   51  President                                                1993\\nWilliam O. Albertini.......   50  Vice President and Chief Financial Officer               1991\\nJoseph T. Ambrozy..........   54  Vice President - Strategic Planning                      1992\\nLawrence T. Babbio, Jr.....   49  Chairman, President and Chief Executive Officer,         1991\\n                                        Bell Atlantic Enterprises International, Inc.\\nP. Alan Bulliner...........   50  Vice President - Corporate Secretary and Counsel         1992  \\nBarbara L. Connor..........   43  Vice President - Finance and Controller and Treasurer    1993 \\nCharles W. Crist...........   50  Vice President - Human Resources                         1990 \\nJohn F. Gamba..............   55  Group President, Network Technologies and Systems,       1993\\n                                        Bell Atlantic Network Services, Inc.\\nBruce S. Gordon............   48  Group President - Consumer and Small Business Services,  1993\\n                                        Bell Atlantic Network Services, Inc.               \\nStuart C. Johnson..........   51  Group President, Large Business and Information          1993\\n                                        Services, Bell Atlantic Network Services, Inc.     \\nBrian J. Kelly.............   59  Group President, Network Operations,                     1993\\n                                        Bell Atlantic Network Services, Inc.               \\nRobert M. Valentini........   50  President and Chief Executive Officer, Bell Atlantic -   1988\\n                                        Pennsylvania, Inc.\\nJames R. Young.............   42  Vice President and General Counsel                       1992\\n'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[3].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html)\n",
    "table = soup.find(\"table\", attrs={\"class\":\"details\"})\n",
    "\n",
    "# The first tr contains the field names.\n",
    "headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "\n",
    "datasets = []\n",
    "for row in table.find_all(\"tr\")[1:]:\n",
    "    dataset = zip(headings, (td.get_text() for td in row.find_all(\"td\")))\n",
    "    datasets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##8-k\n",
    "test_html = 'https://www.sec.gov/Archives/edgar/data/732712/0000950109-94-000587.txt'\n",
    "test_file = request.urlopen(test_html).read().decode('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
